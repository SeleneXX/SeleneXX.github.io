# MySQL面试

## 1. B树和B+树

- B树是一颗节点内可以有多个元素的树，通过max_degree设置每一个节点可以向下扩展出子节点的个数，先序序列是从小到大按顺序的。每一个节点上的多个元素也是从小到大。每个节点上的最多元素个数是max_degree-1。

  下图是一颗max_degree=3的B树

  ![image-20230330150511185](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330150511185.png)

- B+树是一种特殊的树，依旧按照B树的规则，拥有max_degree和顺序限制。此外，B+树的每一个非叶节点，都有一个冗余的叶节点与之对应，所以B+树上存的每一个元素都在叶子节点上存在并通过指针有序相连。

  下图是一颗max_degree=3的B+树

  ![image-20230330150852948](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330150852948.png)

## 2. MySQL中的B+树

- MySQL中的B+树并不是传统定义的B+树，而是由B树改进，没有冗余的叶节点，并且相邻叶子节点之间通过双向指针相连。

  ![image-20230330151315708](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330151315708.png)

## 3. innodb的页

- innodb中的page：大小为16kb。innodb向磁盘读，存数据时，最小的单位是一页。一次取一页数据，在进行数据操作是，可以减少磁盘和内存间的IO操作数量。使用innodb的时候建议使用自增的主键，减少插入或者换页时所需要的断链重连改页操作。两页之间使用next指针连接。

- 页的结构中的关键：页头，User Record和Page Directory。

  ![image-20230330152726531](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330152726531.png)

  - User Record是一个类似list的数据结构。用户insert数据时，数据会存放在page中的user record部分，当达到16kb大小后，就将这一页存入磁盘。在插入数据时，会对数据行自动按照主键大小升序 排序，所以在无条件查询时，结果会自动按照主键排序。

  - 由于user record是用类似链表的方式存储数据，所以遍历性能很差。使用page directory，加速查找。对user record中的数据进行分组，将每组第一个元素的指针和序号存入页目录。空间换时间。

    ![image-20230330155632020](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330155632020.png)

## 4. 页的索引和B+树

- page内部通过page directory优化链表，但是页的存放依旧是链表，并且换页需要进行磁盘IO。可以使用类似页目录的方法，新开一页用于存储所有页的索引，保存每一页最小的元素和对应的指针。

  ![](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330162836947.png)

  这种结构就是innodb中的B+树，共有两层，根节点是索引页，每一个索引对应一个叶节点页面，每一个叶节点页面都有指针指向相邻页面。两层的B+树，索引页可以存16kb/10个页面，10为6个字节的指针加四个字节的int。每个索引页可以存储1638页。假设一条数据大小为1kb，那么总共就可以存储1638*16kb/1kb=26208条数据。

  ![image-20230330164004966](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330164004966.png)

  假设使用3层的B+树，类似的，根节点变成两层B+树根节点的索引。可以存1638*26208条数据。  

  主键索引结构只能对一个键值（主键）进行索引（从上往下），当要查询的条件不是主键时，遍历叶节点链表。这就是全表扫描（从左往右）。如果查找主键大于或小于某一个值，则直接通过索引找到目标主键然后返回左侧或右侧的所有数据即可。为了方便小于条件的查找，innodb在每页之间使用双向指针。

## 5. 自定义索引

- 可以自定义索引，新生成一个额外的B+树，按照table后面字段的顺序依次排序，字段相同则按照次要字段排序。

  ````sql
  create index idx_t1 on table1(key1, key2, key3);
  ````

  ![image-20230330192941743](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330192941743.png)

  但是这样直接存数据，每次新建一个索引，就意味着要把整个表全部复制一遍。如果要修改某个字段，要对整个索引进行改动。

  改进方法：在叶节点，可以不用存完整的数据，只保存字段```key1, key2, key3```，然后一一对应的绑定该叶节点的主键。这样通过索引可以找到主键值，然后通过主键值再去主键索引获取数据。这种通过主键再去主键索引取数据的方法，叫做回表。

  ![image-20230330193429700](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230330193429700.png)

- 最左前缀原则：如果查询时的where条件包含该按照创建某索引时输入的第一个（最左边的）字段，那么就可以使用该索引。要使用某个索引，则在查询条件中必须有该索引的第一个字段，后面的字段可有可没有。

  例如：

  ```sql
  select * from t1 where key3=1 and key1=1;		-- 可以使用建立的的idx_t1索引
  select * from t1 where key2=1 and key3=1;		-- 不能使用建立的的idx_t1索引
  ```

  Using index condition: 在MySQL5.6以前的版本，是不能通过多字段建立的索引的后续值，过滤出符合要求的数据的，而是要全部回表，再进行过滤。再后续版本中，可以直接利用索引后续的字段进行过滤，过滤完最后回表得到结果。这就是using index condition。

## 6. 范围查找索引失效

- 自定义字段key1的索引后，查找所有key1>1的完整数据。

  ````sql
  select * from table1 where key1>1
  ````

- 这个时候，由于需要先查到key1对应的索引后取出所有key1>1的主键值，再拿这些值回表，导致效率极低，可能没有全表扫描快。

-  所以使用索引进行范围搜索时，范围越精确越好，否则要大规模回表，最终导致MySQL选择全表扫描。

## 7. 覆盖索引

- 如果不需要查找完整数据，只查找索引内存储的数据 (key1, key2, key3 + 对应存储的主键），就可以走索引查找。这个叫using index，覆盖索引，也就是直接利用索引数据，不需要回表。如果带上任何其他没有再索引上的字段，就需要进行全表扫描。

  ```sql
  select key1, key2 from table1 where key1>1;
  ```

## 8. 索引扫描的底层原理

- 如果只查找部分索引而没有条件限制

  ````sql
  select key1, key2 form table1;
  ````

  这时，由于没有条件，所以都是从叶节点进行横向扫描。但是由于我们建立 (key1, key2, key3) 的索引并且这些索引没有存储完整的数据而是只存了对应的字段，所以在该索引中，相比主键索引，该索引的page上可以存储更多条目，所以扫描时会遍历更少的页。所以会优先扫描新建索引的叶节点而不对主键索引执行全表扫描。

## 9. order by导致索引失效

- 查询所有的数据并使用order by对目标字段排序

  ````sql
  select * from table1 order by key1, key2, key3;
  ````

  由于此时，没有where条件，所以需要从左往右扫描叶节点。这时，有两种情况：

  - 全表扫描主键索引，在内存中对key1，key2，key3进行排序
  - 扫描自定义索引，由于定义时已经按照key1，key2，key3排序与， 无需排序，但需要对所有数据进行回表

  当数据很少时，排序耗时可以忽略不计，但回表需要消耗很多时间，所以MySQL选择全表扫描

- 查询某一字段并使用order by进行排序

  ```sql
  select key1 from table1 order by key1, key2, key3;
  ```

  这时，由于不需要扫描完整数据，所以走自定义索引时不需要回表。MySQL选择走自定义索引

## 10. 数据类型转换

- key4字段为varchar类型，对key4字段建立索引

  ```sql
  create index idx_t1_key4 on table1(key4);
  ```

  ![image-20230331171329233](C:\Users\Selene\AppData\Roaming\Typora\typora-user-images\image-20230331171329233.png)

  ```sql
  select * from table1 where primary_key = 1;
  select * from table1 where key4 ="1";
  ```

  上述查询语句可以走索引，第一个走主键索引，第二个走key4字段的自定义索引。

  由于MySQL中，强制转换不是由数字组成的字符串成int类型，结果都是0。

  ```sql
  select 'a'=0;			-- 因为字符a转化为int类型为0，所以等式成立，返回1
  select 'a'=1;			-- 因为字符a转化为int类型为0，所以等式不成立，返回0
  select "123"=123;		-- 因为字符串123由数字组成，转化为int依然为123，所以等式成立，返回1
  ```

  所以，在下列查询语句：

  ```sql
  select * from table1 where primary_key = "1";
  select * from table1 where key4 = 1;
  ```

  第一句可以走索引，因为字符1转化为int还是1，所以可以走主键索引。

  第二句走全表扫描，由于key4是varchar类型，进行条件语句时，需要把所有的key4字段存储的字符串，全部转化为int，再去进行筛选。如果走索引，首先要把key4全部转换为int类型，改了字段而非条件右侧的值，那么该索引B+树会因为字段被修改而破坏，所以MySQL选择全表扫描。

  所以只要对字段进行任何操作，就没有办法走索引，只能全表扫描。

  ```sql
  select * from table1 where primary_key + 1 = 1
  ```


## 11. ACID 原子性，一致性，持久性，隔离性

Innodb存储引擎，在引擎级别拥有两个日志，undo log和redo log。MySQL级别，有bin log日志。ACID是数据库内数据的四种特性：

- 原子性：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部都执行，要么都不执行。由undo log保证，记录了需要回滚的信息，撤销已经成功执行的sql。
- 一致性：指在事务开始之前和事务结束以后，数据不会被破坏。一致性由其他三大特性保证，程序代码要保证业务上的一致性。
- 持久性：表示事务完成提交后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。由MVCC来保证。
- 隔离性：多个事务并发访问时，事务之间是相互隔离的，一个事务不应该被其他事务干扰，多个并发事务之间要相互隔离。由内存+redo log来保证。MySQL在修改数据的同时在内存和redo log记录这次操作，如果宕机，可以从redo log恢复。

InnoDB redo log写盘，InnoDB事务进入prepare状态。

如果prepare成功，bin log写盘，再将事务日志持久化到bin log。如果持久化成功那么InnoDB事务则进入commit状态（在redo log里再写一个commit记录）。redo log的刷盘会在系统空闲时进行。 

## 12. Explain语句(执行计划)结果中各个字段分别表示什么

| id                                                           | select_type                      | table | partitions     | type（最重要）                       | possible-keys  |
| :----------------------------------------------------------- | :------------------------------- | ----- | -------------- | ------------------------------------ | -------------- |
| 查询语句每出现一个select关键字，MySQL就会为它分配一个·唯一的id，某些子查询会被优化为join查询，那么出现的id会一样 | select关键字对应的那个查询的类型 | 表名  | 匹配的分区信息 | 针对单表的查询方式（全表扫描，索引） | 可能用到的索引 |

| key            | key_len                                        | ref                                                          | rows                     | filtered                                                     | Extra              |
| -------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------ | ------------------------------------------------------------ | ------------------ |
| 实际使用的索引 | 实际使用的索引长度（使用联合索引中字段的个数） | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息（数据库.表.字段） | 预估的需要读取的记录条数 | 某个表经过搜索条件过滤后剩余记录条数的百分比（读取行数和返回行数的百分比，越高越好） | 额外信息，比如排序 |

Extra：

- using filesort：使用mysql对结果进行外部排序，不能通过索引达到排序效果。建议优化掉，cpu资源和时间消耗大
- using index：覆盖索引
- using temporary：使用临时表，一般出现于排序，分组和多表join的情况，建议优化
- using where：使用where过滤，效率高

type：

- const：通过索引一次命中，匹配一行数据：id=1
- system：表中只有一行记录，系统表，const的特殊情况，比const效率更高
- eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配
- ref：非唯一索引扫描。ref和eq_ref都有可能要回表
- range：检索给定范围的行，使用一个索引来选择行，between，<，>
- index：只遍历了索引树，所有的索引都会遍历
- ALL：全表扫描

## 13. InnoDB是如何实现事务的

InnoDB会通过Buffer Pool，LogBuffer，Redo Log，Undo Log来实现事务。

执行一条update语句：

- Innodb在收到update语句后，会先根据条件找到数据所在的页面，并将该页面缓存在Buffer Pool中
- 执行update语句，修改Buffer Pool中的数据，也就是内存中的数据
- 针对update语句生成Redo Log日志并存入LogBuffer中
- 针对update语句生成Undo Log日志，用于事件回滚
- 如果事务提交，那么则把Redo Log进行持久化，后续还有其他机制将Buffer Pool中所修改的数据页持久化到磁盘中
- 如果事务回滚，则利用Undo Log进行回滚

## 14. 聚簇索引和非聚簇索引

##### 聚簇索引：

数据和索引是在一起的。InnoDB采用聚簇索引，叶节点上存储的是数据本身。叶节点上的数据顺序，就是物理地址的顺序，相邻叶节点物理地址也相邻。

优势：

- 查询效率更高，因为可以直接查到数据，索引覆盖除外。
- 范围查询效率高，因为数据在物理地址上相邻
- 适合用在排序场合

缺点：

- 维护代价高
- 使用随机ID作为主键会导致数据存储稀疏，所以最好用auto_increment的主键

##### 非聚簇索引：

数据和索引分开。MyISAM使用非聚簇索引，树的叶节点上存储的是数据存放的地址。

聚簇索引的数据物理存放顺序和索引顺序是一致的，所以一个表中只有一个聚簇索引，可以建立多个自定义的辅助索引（非聚簇索引）。

InnoDB中，如果定义了主键PK，那PK就是聚簇索引。如果没有主键，就会找第一个非空的Unique字段作为聚簇索引。否则InnoDB会创建一个隐藏的row-id作为聚簇索引。

## 15. 索引覆盖和回表

##### 索引覆盖：如果只需要在一颗索引树上就可以获取SQL所需要的所有列，就不需要回表查询，这样查询速度更快。

实现所引覆盖最简单的方式就是将要查询的字段全部建立到联合索引中。

##### 建立过多索引的坏处

- 不能建立过多的索引。会导致索引表过多，难以管理，查询速度很慢。
- 不能建立字段过多的联合索引。会导致树上分支条件过多，树变得非常庞大。

## 16. MySQL的锁

##### 锁的分类：

- 记录锁：行锁的一种，只可以锁表中的1条记录，精准命中，命中的条件字段是唯一索引。

- 行锁：可以锁多行。加锁粒度小。资源开销大。InnoDB才支持。

  - 共享锁：读锁。多个事务可以对同一个数据共享同一把锁。持有锁的事务都可以访问数据，但是只能读不能修改。普通的select语句不加锁。其他事务只能读不能写。保证并发读取。

    普通select语句是快照读，并不会被读锁写锁限制。

    ````sql
    select xxx from xxx LOCK IN SHARE MODE
    ````

  - 排他锁：写锁。只有一个事务能够获得排他锁，其他事务都不能获取该行的锁。InnoDB会对update、delete、insert语句自动添加排他锁。其他事务不能读不能写。

    手动添加：

    ```sql
    select xxx from xxx FOR UPDATE
    ```

  - 自增锁。针对MySQL中的自增字段。如果有事务回滚，数据会回滚，但是自增序列不会回滚。

- 页锁：锁定一页。

- 表锁：加锁粒度大。资源开销小。MyISAM和InnoDB都支持。

  - 表共享读锁
  - 表排他写锁
  - 意向锁：InnoDB自动添加。当用户对行加锁时，InnoDB会自动对表加意向锁表示即将进行 行操作。

- 全局锁

  ````sql
  Flush tables with read lock
  ````

  加锁之后整个数据库实例处于只读状态。所有的数据变更操作都被挂起。一般用在全库备份的场景。

##### 常见的锁算法：

userid: 1, 4, 9

- 记录锁：锁一条具体的数据。1, 4, 9
- 间隙锁：RR隔离级别加锁。锁一定的范围，左开右闭，而不是具体记录，防止产生幻读。(-inf, 1), (1, 4), (4, 9), (9, inf)
- Next-key：间隙锁+右记录锁 (-inf, 1], (1, 4], (4, 9], (9, inf)

##### 乐观锁和悲观锁：

- 乐观锁：不会真正锁某行记录，而是通过一个版本号来实现的
- 悲观锁：上面的行锁表锁等都是悲观锁。

## 17. 集群和读写分离

- MySQL主从集群可以提高容错，主节点挂了可以继续使用从节点：
  - 主节点每次操作都会存储到Bin log
  - 主节点把这个bin log同步给从节点（master log dump）
  - 从节点拿到bin log的数据写到自己的relay log（slave IO）
  - 从节点新开一个线程去重演log中的操作（slave sql）
- 上述操作涉及到三个线程：
  - master log dump
  - slave IO
  - slave SQL

- 每次进行增量同步，binlog文件+position偏移量确定该次同步的位置

- MySQL主从集群只会将bin log从主节点同步到从节点，而不会反过来。由此引申除了读写分离。
- 要保证主从之间的数据一致，写数据的操作只能在主节点完成。而读数据可以在主节点或从节点上完成。由主从分摊读指令的负载，可以提高数据库的性能。
- 默认使用异步复制集群，主节点发送bin log，并不会检查从节点接受到的数据有没有丢失。同步复制引入了类似三次握手的机制，全同步复制需要等所有从库执行完所有log后响应，主库才认为同步操作完成；半同步机制是只要有有一个从库写入日志后返回ACK给主库，主库就认为同步操作完成。

## 18. MySQL慢查询怎么优化

- 查看该查询是否走了索引，如果没有，就优化SQL使其可以走索引
- 是否用了最优索引
- 检查查询的字段是否都是必须的，是否查询了过多字段查出了多余的数据
- 检查表中数据是否过多，是否需要分库分表
- 数据库实例所在的机器的性能过低
- 通过读写分离，分摊读指令的负载到主从集群。

## 19. 索引失效原因

- 没有符合最左前缀原则
- 字段进行了隐式的数据类型转换：见10.
- 走索引没有全表扫描效率高：
  - 范围查询，见6.
  - order by，见9

## 20. 索引常见的数据结构

- B+树：平衡多叉树，从根节点到不同叶子节点的查询效率相近；也可以直接基于底部叶子节点之间的双向指针直接进行按序扫描叶子节点。
- 哈希索引：绝大多数查询为单条查询时，才适合使用哈希索引。没有办法利用索引完成排序，进行范围查询，以及like语句模糊查询（类似范围查询），不支持最左前缀。如果有大量重复键，哈希冲突，效率极低。

## 21. MySQL的数据存储引擎

通过```show ENGINES```可以显示MySQL的所有引擎

- InnoDB：支持事务，ACID。每个表只有一个文件。支持行锁，外键，事务。支持XA事务，支持savePoints（部分回滚）。聚簇索引。适合做写操作。最好使用自增主键
- MyISAM：不支持事务，每次查询都是原子的。每个表有两个文件，MYD是数据文件，MYI是索引文件。支持表锁。存储了数据总行数，count效率高。非聚簇索引。适合做查询。

## 22. 存储拆分后解决唯一主键

单表时，只要id自增，PK就是唯一的。

分布式场景拆分表后，两张表的id都是自增的，主键就会重复。

解决方案：

- 基于UUID：```UUID()```函数是MySQL中用于生成通用唯一标识符（UUID）的函数。UUID是一种用于标识实体的128位数字。生成的UUID是随机的，并且几乎不可能出现重复的情况。
  - 性能高
  - 由于随机，所以没有顺序，不适合作为InnoDB的主键，无法进行范围查询。
  - 为了保证UUID的随机，生成需要硬件上的某些唯一的信息，比如mac地址，可能会泄露。
- 数据库主键：多个表的pk初始值不一致，步长一致，如```1357```，```2468```。难以扩展，因为初始值和步长必须一开始就定好。
- redis，mongodb，zk等中间件：增加系统复杂度
- 雪花算法

## 23. 海量数据下，如何快速查找一条记录

1. 使用bloom filter，快速过滤不存在的记录

   - 使用Redis的bitmap结构来实现布隆过滤器

2.  在redis中建立数据缓存

   - 以普通字符串来存储
   - 以一个hash来存储一条记录：userid作为key，userdata.json做value

   缓存击穿：bloom filter存在false positive rate。对不存在的数据，也建立key。这些key都是经过bloom filter过滤的，一般不会太多，过期时间不能太长。

   缓存过期：定期重建缓存。将热点数据设置成永不过期。使用分布式锁重建缓存。

3. 查询优化

   redis是按槽位分配数据，自己实现槽位计算，找到记录应该分配哎哪台机器上，直接去目标机器上找。

## 24. 索引类型

- 普通索引：允许被索引的数据列包含重复的值
- 唯一索引：保证数据记录的唯一性
- 主键：特殊的唯一索引，一张表只能定义一个主键索引
- 联合索引：覆盖多个字段
- 全文索引

索引的劣势：数据的增删改，除了更改数据空间外，还要修改索引文件。额外占空间。

## 25. 实现分库分表

当表内数据过多或者库的数据吞吐量过大时，没有其他手法优化，只能进行分库分表。

将原本存储与单个数据库上的数据拆分到多个数据库，将原本存储在单张表上的数据拆分到多张表，实现数据切分，提高数据库性能。

- 水平切分：将数据分散到多张表，涉及分区键
  - 分库：每个库结构一样，数据不一样，没有交集，缓解IO和CPU压力
  - 分表：每个表结构一样，数据不一样，没有交际，提高sql执行效率，减轻CPU压力。
    - 按id切分1-50w，50w-100w。负载不均匀
    - hash：求id的hash值，分散到多个表。难以扩展
- 垂直切分：将字段拆分为多张表，需要一定的重构
  - 分库：每个库结构，数据都不一样，所有库的并集为全量数据
  - 分表：每个表结构，数据不一样，至少有一列交集用于关联数据，所有表的并集为全量数据

## 26. MVCC

MVCC：多版本并发控制。读取数据时，通过类似快照的方式将数据保存下来，这样读写锁不冲突。不同的事务session会看到自己特定版本的数据

#### 四个隔离级别：

- 已提交读Read Commited：可以读取到事务已提交的数据，隔离性一般，不会出现脏读问题，但是会出现不可重复读，幻读问题；
- 可重复读Repeatable Read：可以防止脏读（当前内存读），防止不可重复读问题，防止会出现的幻读问题，但是并发能力较差；
- 未提交读Read Uncommited：可以读取到事务未提交的数据，隔离性差，会出现脏读（当前内存读），不可重复读，幻读问题;
- 串行化Serializable：隔离性比较高，可以实现串行化读取数据，但是事务的并发度就没有了；

MVCC只在READ COMMITTED（已提交读）和REPEATABLE READ（可重复读）隔离级别下工作。未提交读总是读取最新的数据行，而不是符合当前事务版本的数据。而serializable会对所有读取的行都加锁。

聚簇索引中有两个必要的隐藏列：

- trx_id：用来存储每次对某条聚簇索引记录进行修改的事务id
- roll_pointer：每次哪条聚簇索引记录有修改时，都会把老版本写入undo日志中，这个roll_pointer就存了一个指针，指向这条聚簇索引记录的上一个版本的位置

版本链

| id   | name  | trx_id | roll_pointer     |
| ---- | ----- | ------ | ---------------- |
| 1    | 小明2 | 100    | 上一个版本的地址 |
|      |       |        |                  |
| 1    | 小明1 | 60     | 上一个版本的地址 |
|      |       |        |                  |
| 1    | 小明  | 50     |                  |

MVCC就是版本链+ReadView。

已提交读和可重复读的区别在于它们生成的ReadView策略不同。

开始创建事务时，创建readview，readview维护了当前活动的事务id，即未提交的事务id，排序生成一个数组访问数据

访问数据链，获取数据中的事务id最大的记录（最新），对比readview。

- 如果比readview小，readview从小到大排列，那说明这个事务已经提交完毕，获取这条数据作为快照。

- 如果比readview大，或者出现在readview中，那么该数据不可访问，获取roll_pointer，取上一版本的数据重新对比

已提交读在每一次查询时的开始时都会生成一个独立的readview用于对比，所以每次重新查询，都会生成新的readview，每次可读取的数据都不一样，所以又叫不可重复读。性能低

可重复读则是在第一次读的时候生成一个readview。之后都复用之前的readview。性能高

## 27. 脏读，幻读，不可重复读

都是MySQL进行事务并发控制时经常遇到的问题

#### 脏读：在事务进行过程中，读到了其他事务未提交的数据

#### 不可重复读：在一个事物的过程中，多次查询的结果不一致（update，读到的数据和上一次不一致）

#### 幻读：在同一个事务中，用同样的操作查询数据，得到的记录数不同（insert，读到了原来不存在的数据）

解决方法：加锁，事务隔离，MVCC

加锁（不太好）：

- 脏读：修改时加排他锁，直到事务提交才释放。读取时加共享锁，读完释放。
- 不可重复读：读数据时，加共享锁，写数据时加排他锁。
- 幻读：加间隙锁。

## 28. 索引的设计原则

使得查询更快，占用空间更小

- 适合索引出现的列是出现在where句子中的列，或者是连接查询时指定的列（join on）
- 基数较小的表，索引效果比较差，没必要简历索引。
- 使用短索引，如果对长字符串进行索引，指定一个前缀长度，这样可以大量节省索引空间
- 不要过度索引。
- 定义有外键的数据列一定要建立索引
- 更新频繁的字段不适合建立索引
- 字段区分度很低时，不适合建立索引（字段中可填的值很少，那么相同的值查出来的数据非常多，需要大量回表）
- 尽量扩展索引，不要新建索引。表中已有a索引，那么直接修改原来的索引为联合索引(a,b)而不是新建索引
- 对于查询中很少涉及的列（不出现在where和join on中），重复值比较多的列（区分度低），不要建立索引。
- 对于text，image，bit的数据类型，不要建立索引
